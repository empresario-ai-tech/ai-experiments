{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/empresario-ai-tech/ai-experiments/blob/dec-1-explore-embeddings/Embeddings/embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoki8R28EMGP",
        "outputId": "35052e1a-2743-4efd-95c7-eb56fc11f2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhWcuRtdDnw4"
      },
      "outputs": [],
      "source": [
        "!pip install -r '/content/drive/MyDrive/Colab Notebooks/Embeddings/requirements.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENDjNt64GyV1"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnu6m5-LYlky"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiUmuNPsZs9i"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.21.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4xTfeQkZwwR"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib thinc gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJsFCaYratQr"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-cpu==2.11.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgv1NobdaVsM"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio torch_xla"
      ],
      "metadata": {
        "id": "ZGrZ2DEqHGDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch, TorchVision, and TorchAudio\n",
        "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Install torch_xla\n",
        "!pip install torch_xla==2.0.1 -f https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "Jw3kMg1RHTvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lTPBp-I9zZh1"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import pickle\n",
        "import torch\n",
        "try:\n",
        "    import torch_xla.core.xla_model as xm\n",
        "except ImportError:\n",
        "    xm = None\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/Embeddings\"\n",
        "EMBEDDINGS_PATH = '/content/ingredient_embeddings.pkl'\n",
        "STANDARDIZED_INGREDIENTS_FILE = f'{DATA_PATH}/standardized_ingredients_dummy.csv'\n",
        "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
        "BATCH_SIZE = 1000\n",
        "THRESHOLD = 0.7\n",
        "\n",
        "USER_INGREDIENTS = [\n",
        "    \"all purpose flour\",\n",
        "    \"gran sugar\",\n",
        "    \"olive oil\",\n",
        "    \"black pepper\",\n",
        "    \"chicken breasts\",\n",
        "    \"eggs\",\n",
        "    \"milk\",\n",
        "    \"butter\"\n",
        "]\n",
        "\n",
        "AI_INGREDIENTS = [\n",
        "    \"all-purpose flour\",\n",
        "    \"granulated sugar\",\n",
        "    \"extra virgin olive oil\",\n",
        "    \"black pepper\",\n",
        "    \"chicken breast\",\n",
        "    \"egg\",\n",
        "    \"whole milk\",\n",
        "    \"unsalted butter\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NYWEQzDiFglR"
      },
      "outputs": [],
      "source": [
        "# Define IngredientEmbeddings class\n",
        "class IngredientEmbeddings:\n",
        "    def __init__(self, model_name=MODEL_NAME, batch_size=BATCH_SIZE):\n",
        "        self.device = self.get_device()\n",
        "        self.model = SentenceTransformer(model_name).to(self.device)\n",
        "        self.batch_size = batch_size\n",
        "        self.standardized_ingredients = None\n",
        "        self.embeddings = None\n",
        "        self.index = None\n",
        "\n",
        "    def get_device(self):\n",
        "        if torch.cuda.is_available():\n",
        "            return 'cuda'\n",
        "        else:\n",
        "            return 'cpu'\n",
        "\n",
        "    def load_standardized_ingredients(self):\n",
        "        return pd.read_csv(STANDARDIZED_INGREDIENTS_FILE)\n",
        "\n",
        "    def generate_embeddings(self):\n",
        "        all_embeddings = []\n",
        "        for chunk in tqdm(pd.read_csv(STANDARDIZED_INGREDIENTS_FILE, chunksize=self.batch_size), desc=\"Generating Embeddings\"):\n",
        "            chunk_embeddings = self.model.encode(\n",
        "                chunk['ingredient_name'].tolist(),\n",
        "                convert_to_tensor=True,\n",
        "                show_progress_bar=False,\n",
        "                device=self.device\n",
        "            )\n",
        "            all_embeddings.append(chunk_embeddings.cpu().numpy())\n",
        "        return np.vstack(all_embeddings)\n",
        "\n",
        "    def build_faiss_index(self):\n",
        "        dimension = self.embeddings.shape[1]\n",
        "        index = faiss.IndexFlatL2(dimension)\n",
        "        index.add(self.embeddings)\n",
        "        return index\n",
        "\n",
        "    def save_embeddings(self, path=EMBEDDINGS_PATH):\n",
        "        ingredient_data = self.load_standardized_ingredients()\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'ingredients': ingredient_data,\n",
        "                'embeddings': self.embeddings,\n",
        "                'index': self.index\n",
        "            }, f)\n",
        "\n",
        "    def load_embeddings(self, path=EMBEDDINGS_PATH):\n",
        "        with open(path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.standardized_ingredients = data['ingredients']\n",
        "            self.embeddings = data['embeddings']\n",
        "            self.index = data['index']\n",
        "\n",
        "    def initialize_embeddings(self):\n",
        "        self.embeddings = self.generate_embeddings()\n",
        "        self.index = self.build_faiss_index()\n",
        "        self.standardized_ingredients = self.load_standardized_ingredients()\n",
        "\n",
        "# Define IngredientMatcher class\n",
        "class IngredientMatcher:\n",
        "    def __init__(self, threshold=THRESHOLD):\n",
        "        self.threshold = threshold\n",
        "        self.device = self.get_device()\n",
        "        self.embeddings = IngredientEmbeddings()\n",
        "\n",
        "        if os.path.exists(EMBEDDINGS_PATH):\n",
        "            self.embeddings.load_embeddings(EMBEDDINGS_PATH)\n",
        "        else:\n",
        "            self.embeddings.initialize_embeddings()\n",
        "            self.embeddings.save_embeddings(EMBEDDINGS_PATH)\n",
        "\n",
        "    def get_device(self):\n",
        "        if torch.cuda.is_available():\n",
        "            return 'cuda'\n",
        "        else:\n",
        "            return 'cpu'\n",
        "\n",
        "    def get_embedding(self, ingredient):\n",
        "        model = self.embeddings.model.to(self.device)\n",
        "        return model.encode(\n",
        "            [ingredient],\n",
        "            convert_to_tensor=True,\n",
        "            device=self.device\n",
        "        ).cpu().numpy()\n",
        "\n",
        "    def match_ingredient(self, ingredient):\n",
        "        query_embedding = self.get_embedding(ingredient)\n",
        "        distances, indices = self.embeddings.index.search(query_embedding, 1)\n",
        "        closest_distance = distances[0][0]\n",
        "        closest_index = indices[0][0]\n",
        "        similarity = 1 / (1 + closest_distance)\n",
        "        if similarity >= self.threshold:\n",
        "            matched_name = self.embeddings.standardized_ingredients.iloc[closest_index]['ingredient_name']\n",
        "            return matched_name, similarity\n",
        "        else:\n",
        "            return None, similarity\n",
        "\n",
        "    def match_ingredients_list(self, ingredients):\n",
        "        matched = {}\n",
        "        for ingredient in ingredients:\n",
        "            match, score = self.match_ingredient(ingredient)\n",
        "            matched[ingredient] = {\n",
        "                'matched_name': match,\n",
        "                'similarity': score\n",
        "            }\n",
        "        return matched\n",
        "\n",
        "# Main logic to standardize ingredients\n",
        "def standardize_ingredients(user_ingredients, ai_ingredients):\n",
        "    matcher = IngredientMatcher(threshold=THRESHOLD)\n",
        "\n",
        "    print(\"Matching User Ingredients...\")\n",
        "    matched_user = matcher.match_ingredients_list(user_ingredients)\n",
        "\n",
        "    print(\"Matching AI-Generated Ingredients...\")\n",
        "    matched_ai = matcher.match_ingredients_list(ai_ingredients)\n",
        "\n",
        "    return matched_user, matched_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Jg2GBimDnw7"
      },
      "outputs": [],
      "source": [
        "# Execute the main logic\n",
        "matched_user, matched_ai = standardize_ingredients(USER_INGREDIENTS, AI_INGREDIENTS)\n",
        "\n",
        "print(\"\\nMatched User Ingredients:\")\n",
        "for k, v in matched_user.items():\n",
        "    print(f\"{k} -> {v['matched_name']} (Similarity: {v['similarity']:.2f})\")\n",
        "\n",
        "print(\"\\nMatched AI-Generated Ingredients:\")\n",
        "for k, v in matched_ai.items():\n",
        "    print(f\"{k} -> {v['matched_name']} (Similarity: {v['similarity']:.2f})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}