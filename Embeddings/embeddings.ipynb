{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/empresario-ai-tech/ai-experiments/blob/dec-1-explore-embeddings/Embeddings/embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "DATA_PATH = os.path.join(BASE_DIR, 'data') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTPBp-I9zZh1"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import pickle\n",
        "# from .utils import DATA_PATH\n",
        "\n",
        "class IngredientEmbeddings:\n",
        "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.standardized_ingredients = self.load_standardized_ingredients()\n",
        "        self.embeddings = self.generate_embeddings()\n",
        "        self.index = self.build_faiss_index()\n",
        "\n",
        "    def load_standardized_ingredients(self):\n",
        "        df = pd.read_csv(f\"{DATA_PATH}/standardized_ingredients.csv\")\n",
        "        return df['ingredient_name'].tolist()\n",
        "\n",
        "    def generate_embeddings(self):\n",
        "        embeddings = self.model.encode(self.standardized_ingredients, convert_to_tensor=True, show_progress_bar=True)\n",
        "        return embeddings.cpu().numpy()\n",
        "\n",
        "    def build_faiss_index(self):\n",
        "        dimension = self.embeddings.shape[1]\n",
        "        index = faiss.IndexFlatL2(dimension)\n",
        "        index.add(self.embeddings)\n",
        "        return index\n",
        "\n",
        "    def save_embeddings(self, path='data/ingredient_embeddings.pkl'):\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'ingredients': self.standardized_ingredients,\n",
        "                'embeddings': self.embeddings,\n",
        "                'index': self.index\n",
        "            }, f)\n",
        "\n",
        "    def load_embeddings(self, path='data/ingredient_embeddings.pkl'):\n",
        "        with open(path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self.standardized_ingredients = data['ingredients']\n",
        "            self.embeddings = data['embeddings']\n",
        "            self.index = data['index'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "class IngredientMatcher:\n",
        "    def __init__(self, threshold=0.7):\n",
        "        self.threshold = threshold\n",
        "        self.embeddings = IngredientEmbeddings()\n",
        "        try:\n",
        "            self.embeddings.load_embeddings()\n",
        "        except FileNotFoundError:\n",
        "            self.embeddings.generate_embeddings()\n",
        "            self.embeddings.save_embeddings()\n",
        "    \n",
        "    def get_embedding(self, ingredient):\n",
        "        model = self.embeddings.model\n",
        "        return model.encode([ingredient], convert_to_tensor=True).cpu().numpy()\n",
        "\n",
        "    def match_ingredient(self, ingredient):\n",
        "        query_embedding = self.get_embedding(ingredient)\n",
        "        distances, indices = self.embeddings.index.search(query_embedding, 1)\n",
        "        closest_distance = distances[0][0]\n",
        "        closest_index = indices[0][0]\n",
        "        similarity = 1 / (1 + closest_distance)  # Convert L2 distance to similarity\n",
        "        if similarity >= self.threshold:\n",
        "            return self.embeddings.standardized_ingredients[closest_index], similarity\n",
        "        else:\n",
        "            return None, similarity\n",
        "\n",
        "    def match_ingredients_list(self, ingredients):\n",
        "        matched = {}\n",
        "        for ingredient in ingredients:\n",
        "            match, score = self.match_ingredient(ingredient)\n",
        "            matched[ingredient] = {\n",
        "                'matched_name': match,\n",
        "                'similarity': score\n",
        "            }\n",
        "        return matched "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from src.matcher import IngredientMatcher\n",
        "\n",
        "def standardize_ingredients(user_ingredients, ai_ingredients):\n",
        "    matcher = IngredientMatcher(threshold=0.7)\n",
        "    \n",
        "    print(\"Matching User Ingredients...\")\n",
        "    matched_user = matcher.match_ingredients_list(user_ingredients)\n",
        "    \n",
        "    print(\"Matching AI-Generated Ingredients...\")\n",
        "    matched_ai = matcher.match_ingredients_list(ai_ingredients)\n",
        "    \n",
        "    return matched_user, matched_ai\n",
        "\n",
        "\n",
        "user_ingredients = [\n",
        "    \"all purpose flour\",\n",
        "    \"gran sugar\",\n",
        "    \"olive oil\",\n",
        "    \"black pepper\",\n",
        "    \"chicken breasts\",\n",
        "    \"eggs\",\n",
        "    \"milk\",\n",
        "    \"butter\"\n",
        "]\n",
        "\n",
        "ai_ingredients = [\n",
        "    \"all-purpose flour\",\n",
        "    \"granulated sugar\",\n",
        "    \"extra virgin olive oil\",\n",
        "    \"black pepper\",\n",
        "    \"chicken breast\",\n",
        "    \"egg\",\n",
        "    \"whole milk\",\n",
        "    \"unsalted butter\"\n",
        "]\n",
        "\n",
        "matched_user, matched_ai = standardize_ingredients(user_ingredients, ai_ingredients)\n",
        "\n",
        "print(\"\\nMatched User Ingredients:\")\n",
        "for k, v in matched_user.items():\n",
        "    print(f\"{k} -> {v['matched_name']} (Similarity: {v['similarity']:.2f})\")\n",
        "\n",
        "print(\"\\nMatched AI-Generated Ingredients:\")\n",
        "for k, v in matched_ai.items():\n",
        "    print(f\"{k} -> {v['matched_name']} (Similarity: {v['similarity']:.2f})\") "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONVvF52KJKQkx5YbLn7JtQ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
